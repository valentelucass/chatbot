<!-- PORTFOLIO-FEATURED
title: Chatbot para Estudantes
description: Chatbot full-stack para auxiliar estudantes em dÃºvidas de programaÃ§Ã£o e estudos gerais, com base local e fallback via OpenAI.
technologies: Python, FastAPI, JavaScript, HTML5, CSS3
demo: https://chatbot-ten-pi-24.vercel.app/
highlight: true
image: chatbot.png
-->

<p align="center">
  <img src="chatbot.png" alt="Capa do projeto" width="1200">
</p>

# Chatbot para Estudantes

ğŸ”— [Acesse o chatbot online](https://chatbot-ten-pi-24.vercel.app/)

Este projeto Ã© um **chatbot simples e escalÃ¡vel**, projetado para ajudar estudantes com dÃºvidas sobre programaÃ§Ã£o e outros tÃ³picos de estudo. A arquitetura foi pensada para ser **fÃ¡cil de manter, de baixo custo e com deploy simplificado na Vercel**.

---

## âœ¨ VisÃ£o Geral da Arquitetura

O projeto Ã© dividido em duas camadas principais:

* **Frontend**: Interface de chat estÃ¡tica construÃ­da com HTML, CSS e JavaScript puros. ResponsÃ¡vel por exibir a conversa e se comunicar com o backend.
* **Backend**: API em Python usando FastAPI. ContÃ©m a lÃ³gica do chatbot, processando as mensagens dos usuÃ¡rios.

### Fluxo de Funcionamento

1. O usuÃ¡rio envia uma mensagem pelo frontend.
2. O frontend faz uma requisiÃ§Ã£o HTTP POST para o endpoint `/api/chat`.
3. O backend FastAPI recebe a mensagem.
4. A lÃ³gica do chatbot busca primeiro por uma resposta na **base de conhecimento local** (`chatbot.json`).
5. Se nÃ£o houver resposta local, a API da OpenAI (ChatGPT) Ã© usada como fallback.
6. A resposta Ã© retornada em JSON para o frontend, que a exibe na tela.

---

## ğŸš€ Estrutura de DiretÃ³rios

```
chatbot/
â”‚
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py             # Entrada da API (FastAPI)
â”‚   â”œâ”€â”€ chatbot.py          # LÃ³gica do chatbot
â”‚   â”œâ”€â”€ chatbot.json        # Base local de conhecimento
â”‚   â”œâ”€â”€ config.py           # ConfiguraÃ§Ãµes e variÃ¡veis de ambiente
â”‚   â”œâ”€â”€ utils.py            # FunÃ§Ãµes auxiliares
â”‚   â””â”€â”€ __init__.py         # Marca 'api' como pacote Python
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html          # PÃ¡gina de chat
â”‚   â”œâ”€â”€ style.css           # Estilos
â”‚   â””â”€â”€ script.js           # LÃ³gica do frontend
â”‚
â”œâ”€â”€ requirements.txt        # DependÃªncias Python
â”œâ”€â”€ vercel.json             # ConfiguraÃ§Ã£o de deploy Vercel
â”œâ”€â”€ .env                    # VariÃ¡veis de ambiente (nÃ£o versionar)
â”œâ”€â”€ .gitignore              # Arquivos/pastas ignorados pelo Git
â””â”€â”€ README.md               # Este arquivo
```

---

## ğŸ› ï¸ Como Executar Localmente

### PrÃ©-requisitos

* [Python 3.9+](https://www.python.org/downloads/)
* Editor de cÃ³digo (ex.: VS Code)
* Conta OpenAI com API Key (opcional, apenas para fallback ChatGPT)

### Passo a Passo

1. **Clone o repositÃ³rio**

```bash
git clone <url-do-seu-repositorio>
cd chatbot
```

2. **Crie e ative um ambiente virtual**

```bash
# Windows
python -m venv .venv
.\.venv\Scripts\activate

# macOS / Linux
python3 -m venv .venv
source .venv/bin/activate
```

3. **Instale as dependÃªncias**

```bash
pip install -r requirements.txt
```

4. **(Opcional) Configure a variÃ¡vel de ambiente da OpenAI**
   Crie um arquivo `.env` na raiz:

```
OPENAI_API_KEY="sk-...sua_chave_aqui"
```

5. **Inicie o servidor**

```bash
uvicorn api.main:app --reload
```

* Servidor rodando em `http://127.0.0.1:8000`.
* `--reload` reinicia automaticamente ao alterar o cÃ³digo.

6. **Abra o frontend**

* Navegue atÃ© `frontend/` e abra `index.html`.
* Recomenda-se usar **Live Server** no VS Code para evitar problemas de CORS.

---

## ğŸŒ Deploy na Vercel

O deploy Ã© simples:

1. Suba o projeto para GitHub, GitLab ou Bitbucket.
2. No [Vercel](https://vercel.com), clique em "Add New Project" e importe o repositÃ³rio.
3. A Vercel detecta automaticamente Python + FastAPI.
4. (Opcional) Adicione variÃ¡veis de ambiente (`OPENAI_API_KEY`).
5. Clique em **Deploy**. Pronto!

---

## ğŸ“ ConfiguraÃ§Ãµes e VariÃ¡veis

* `OPENAI_API_KEY`: chave da OpenAI (para fallback com ChatGPT)
* `frontend/script.js` detecta automaticamente se estÃ¡ em **localhost** ou produÃ§Ã£o.
* Backend permite CORS para `http://127.0.0.1:5500` e `http://localhost:5500`.

---

## ğŸ”§ Funcionalidades Implementadas

* **Matching local**: busca exata, substring, fuzzy e embeddings (OpenAI opcional)
* **Fallback OpenAI** caso nenhuma resposta local seja encontrada
* **Streaming de respostas** (`/api/chat_stream`) para melhor UX em respostas longas
* **Toggle resposta curta/longa** e "Mostrar mais/menos"
* **Realce de cÃ³digo** com Prism.js no frontend
* **Auto-reload** do `chatbot.json` por mtime
* **Endpoint de diagnÃ³stico**: `GET /api/kb_status`

### Ordem de Matching Local

1. Exato â†’ 2. Substring â†’ 3. Fuzzy (SequenceMatcher + Jaccard) â†’ 4. Embeddings (cos \~0.82)

* Embeddings ativam apenas se `OPENAI_API_KEY` estiver definida.

---

## ğŸ”— Endpoints Ãšteis

* `POST /api/chat` â†’ principal
* `POST /api/chat_stream` â†’ streaming
* `GET /api/kb_status` â†’ status da base local

---
